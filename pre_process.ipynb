{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50899db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsadsadsa\n"
     ]
    }
   ],
   "source": [
    "print(\"dsadsadsa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba9aec18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of          Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0     82450.0  1.314539  0.590643 -0.666593  0.716564  0.301978 -1.125467   \n",
       "1     50554.0 -0.798672  1.185093  0.904547  0.694584  0.219041 -0.319295   \n",
       "2     55125.0 -0.391128 -0.245540  1.122074 -1.308725 -0.639891  0.008678   \n",
       "3    116572.0 -0.060302  1.065093 -0.987421 -0.029567  0.176376 -1.348539   \n",
       "4     90434.0  1.848433  0.373364  0.269272  3.866438  0.088062  0.970447   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "979  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n",
       "980  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n",
       "981  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
       "982  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n",
       "983  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n",
       "\n",
       "           V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0    0.388881 -0.288390 -0.132137  ... -0.170307 -0.429655 -0.141341   \n",
       "1    0.495236  0.139269 -0.760214  ...  0.202287  0.578699 -0.092245   \n",
       "2   -0.701304 -0.027315 -2.628854  ... -0.133485  0.117403 -0.191748   \n",
       "3    0.775644  0.134843 -0.149734  ...  0.355576  0.907570 -0.018454   \n",
       "4   -0.721945  0.235983  0.683491  ...  0.103563  0.620954  0.197077   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "979 -0.882850  0.697211 -2.064945  ...  0.778584 -0.319189  0.639419   \n",
       "980 -1.413170  0.248525 -1.127396  ...  0.370612  0.028234 -0.145640   \n",
       "981 -2.234739  1.210158 -0.652250  ...  0.751826  0.834108  0.190944   \n",
       "982 -2.208002  1.058733 -1.632333  ...  0.583276 -0.269209 -0.456108   \n",
       "983  0.223050 -0.068384  0.577829  ... -0.164350 -0.295135 -0.072173   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "0   -0.200195  0.639491  0.399476 -0.034321  0.031692    0.76      0  \n",
       "1    0.013723 -0.246466 -0.380057 -0.396030 -0.112901    4.18      0  \n",
       "2   -0.488642 -0.309774  0.008100  0.163716  0.239582   15.00      0  \n",
       "3   -0.126269 -0.339923 -0.150285 -0.023634  0.042330   57.00      0  \n",
       "4    0.692392 -0.206530 -0.021328 -0.019823 -0.042682    0.00      0  \n",
       "..        ...       ...       ...       ...       ...     ...    ...  \n",
       "979 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00      1  \n",
       "980 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76      1  \n",
       "981  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89      1  \n",
       "982 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00      1  \n",
       "983 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53      1  \n",
       "\n",
       "[984 rows x 31 columns]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_dir = Path(\"./dataset\")\n",
    "dataset_dir.mkdir(parents=True, exist_ok=True)  # Ensure the directory exists\n",
    "dataset_path = dataset_dir / \"creditcard-data.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "381b76d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "Class\n",
      "0    492\n",
      "1    492\n",
      "Name: count, dtype: int64\n",
      "\n",
      "New class distribution after undersampling:\n",
      "Class\n",
      "0    492\n",
      "1    492\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Undersampled dataset saved as 'creditcard_undersampled.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset (Ensure you have 'creditcard.csv' in your working directory)\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(df[\"Class\"].value_counts())\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df[\"Class\"] == 0]  # Non-fraudulent transactions\n",
    "df_minority = df[df[\"Class\"] == 1]  # Fraudulent transactions\n",
    "\n",
    "# Apply undersampling: Reduce majority class to match minority class size\n",
    "df_majority_undersampled = resample(df_majority, \n",
    "                                    replace=False,    # Sample without replacement\n",
    "                                    n_samples=len(df_minority),  # Match minority class size\n",
    "                                    random_state=42)  # Reproducibility\n",
    "\n",
    "# Combine minority class with undersampled majority class\n",
    "df_undersampled = pd.concat([df_majority_undersampled, df_minority])\n",
    "\n",
    "# Check new class distribution\n",
    "print(\"\\nNew class distribution after undersampling:\")\n",
    "print(df_undersampled[\"Class\"].value_counts())\n",
    "\n",
    "# Save the new dataset\n",
    "#new_dataset_path = dataset_dir / \"creditcard_undersampled.csv\"\n",
    "df_undersampled.to_csv(dataset_path, index=False)\n",
    "print(\"\\nUndersampled dataset saved as 'creditcard_undersampled.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ee18d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df_undersampled.drop(columns=[\"Class\"])\n",
    "y = df_undersampled[\"Class\"]\n",
    "\n",
    "#Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "# Split into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled,y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "# Convert to DataFrame for saving\n",
    "train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "train_df[\"Class\"] = y_train\n",
    "val_df = pd.DataFrame(X_val, columns=X.columns)\n",
    "val_df[\"Class\"] = y_val\n",
    "test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "test_df[\"Class\"] = y_test\n",
    "\n",
    "#logger.info(\"Preprocessed data and split into train, validation, and test sets.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6520e108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File userprefix.json uploaded to models-bucket as uploaded_example.txt\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# MinIO credentials and endpoint\n",
    "endpoint_url = \"http://localhost:9000\"  # Adjust if running remotely\n",
    "aws_access_key_id = \"user\"\n",
    "aws_secret_access_key = \"WW4e69Wwcv0w\"\n",
    "bucket_name = \"models-bucket\"\n",
    "file_path = \"userprefix.json\"\n",
    "object_name = \"uploaded_example.txt\"\n",
    "\n",
    "# Create S3 client\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=endpoint_url,  # MinIO URL\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "\n",
    "# Upload file\n",
    "s3_client.upload_file(file_path, bucket_name, object_name)\n",
    "\n",
    "print(f\"File {file_path} uploaded to {bucket_name} as {object_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_sci (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
